# Semantic Search - Quick Setup Guide

## âœ… Status

### Completed
- âœ“ Generated 9,271 embeddings (text-embedding-3-small, 1536 dimensions)
- âœ“ Embeddings file created: `assets/data/optimized/spectrum-embeddings.json` (289MB)
- âœ“ Configured sqlite-vec extension in app.config.js
- âœ“ Created database migration for vector table
- âœ“ Implemented automatic loading on app startup

### What Happens on First Launch

When you first launch the app after rebuilding:

1. **Migrations run** â†’ Creates `spectrum_vectors` table
2. **Embeddings load** â†’ Inserts 9,271 embeddings from JSON into SQLite
   - Takes ~30-60 seconds on first launch
   - Subsequent launches skip this (cached flag in AsyncStorage)
3. **Semantic search ready** â†’ Tool is available to LLM

Console output:
```
Initializing SQLite database...
Running database migrations...
Running migration 2: create_spectrum_vectors
âœ“ Spectrum vectors table created
âœ“ Migration 2 completed
Loading spectrum embeddings...
Reading embeddings file...
Loaded 9271 embeddings from file
Model: text-embedding-3-small, Dimensions: 1536
Clearing existing embeddings...
  Inserted 500/9271...
  Inserted 1000/9271...
  ...
  Inserted 9000/9271...
âœ“ Successfully inserted 9271 embeddings
âœ“ Embeddings loaded successfully!
âœ“ Spectrum embeddings ready (9271 roots)
âœ“ Database initialized
```

## ðŸš€ Next Steps

### 1. Rebuild the App (Required)

Since we added a native extension (sqlite-vec), you need to rebuild:

```bash
# iOS
npm run build:ios
# OR
npx expo run:ios
```

### 2. Test Semantic Search

Launch the app and go to the Smart (Ø°ÙƒÙŠ) tab. Try questions like:

**Test Query 1: Movement**
```
User: Ù…Ø§Ù‡ÙŠ Ø§Ù„ÙƒÙ„Ù…Ø© Ø§Ù„ØªÙŠ ØªØ¹Ù†ÙŠ Ø§Ù„Ø­Ø±ÙƒØ© ÙˆØ§Ù„Ø§Ù†ØªÙ‚Ø§Ù„ Ù…Ù† Ù…ÙƒØ§Ù† Ø¥Ù„Ù‰ Ø¢Ø®Ø±ØŸ
```

Expected LLM behavior:
1. Calls `search_word_by_meaning({ meaning_query: "Ø§Ù„Ø­Ø±ÙƒØ© ÙˆØ§Ù„Ø§Ù†ØªÙ‚Ø§Ù„ Ù…Ù† Ù…ÙƒØ§Ù† Ø¥Ù„Ù‰ Ø¢Ø®Ø±" })`
2. Gets top 3 roots: e.g., ["Ø°Ù‡Ø¨", "Ø³ÙŠØ±", "Ø±Ø­Ù„"]
3. Requests content for first root
4. Evaluates and provides answer

**Test Query 2: Strength**
```
User: Ø£Ø¨Ø­Ø« Ø¹Ù† ÙƒÙ„Ù…Ø© ØªØ¯Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ù‚ÙˆØ© ÙˆØ§Ù„Ø´Ø¯Ø©
```

**Test Query 3: Water**
```
User: Ø£ÙŠ Ø¬Ø°Ø± ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù…Ø¹Ù†Ù‰ Ø§Ù„Ù…Ø§Ø¡ ÙˆØ§Ù„Ø³ÙŠÙ„Ø§Ù†ØŸ
```

### 3. Monitor Console Logs

Watch for:
- âœ“ "Spectrum embeddings ready (9271 roots)" on first launch
- âœ“ "Generating embedding for query: ..." when tool is called
- âœ“ "Searching spectrum vectors..." during search
- âš  Any errors from embedding service or vector search

## ðŸ”§ Troubleshooting

### Issue: Embeddings not loading

**Symptom**: Console shows "Could not load embeddings"

**Solutions**:
1. Check that `spectrum-embeddings.json` exists in assets folder
2. Verify file size is ~289MB
3. Check console for specific error message
4. Try force reload: Delete app and reinstall

### Issue: Semantic search not working

**Symptom**: LLM doesn't use `search_word_by_meaning` tool

**Solutions**:
1. Verify you're using OpenAI or Google provider (Anthropic/Groq don't support embeddings)
2. Check that embeddings loaded successfully (count should be 9271)
3. Try a clearer query like "Ù…Ø§Ù‡ÙŠ Ø§Ù„ÙƒÙ„Ù…Ø© Ø§Ù„ØªÙŠ ØªØ¹Ù†ÙŠ..." format

### Issue: "extension not found" error

**Symptom**: Error loading sqlite-vec extension

**Solutions**:
1. Verify `app.config.js` has the plugin configured
2. Rebuild the app completely (delete build folder first)
3. Check that you're running on a supported platform (iOS/Android, not web)

### Issue: Slow first launch

**Expected**: First launch takes 30-60 seconds to load 9271 embeddings

**Solutions**:
- This is normal behavior
- Shows loading progress in console
- Subsequent launches are instant (embeddings stay in SQLite)
- If too slow, reduce batch size in EmbeddingLoader (currently 50)

## ðŸ“Š Performance Metrics

### First Launch
- Migration: ~1 second
- Embedding load: ~30-60 seconds (one-time)
- Total: ~60 seconds

### Subsequent Launches
- Check if loaded: <1ms
- Skip loading: instant
- Total: Normal app startup time

### Query Performance
- Embedding generation: ~200ms (API call to OpenAI/Google)
- Vector search: ~50-100ms (native SQLite)
- Root content retrieval: ~10-20ms
- **Total per query: ~300-500ms**

### Storage
- JSON file: 289MB (bundled in app)
- SQLite vectors: ~56MB (9271 Ã— 1536 Ã— 4 bytes)
- Total added to app: ~345MB

## ðŸŽ¯ Usage Tips

### For Best Results

1. **Use clear queries** with the "Ù…Ø§Ù‡ÙŠ Ø§Ù„ÙƒÙ„Ù…Ø© Ø§Ù„ØªÙŠ..." pattern
2. **Be specific** about the meaning you're looking for
3. **Let LLM iterate** - it will try multiple roots if needed
4. **Trust the tool** - LLM knows when to stop searching

### Example Workflows

**Workflow 1: Simple match**
- Query â†’ Search â†’ Found in root #1 â†’ Answer (2 tool calls)

**Workflow 2: Need more context**
- Query â†’ Search â†’ Check root #1 chunk 1 â†’ Need chunk 2 â†’ Answer (4 tool calls)

**Workflow 3: Multiple roots**
- Query â†’ Search â†’ Check root #1 (no match) â†’ Check root #2 â†’ Answer (4 tool calls)

**Workflow 4: Not found**
- Query â†’ Search â†’ Check all 3 roots â†’ No match â†’ Tell user (5 tool calls, hit limit)

## ðŸ“ Notes

- Embeddings are loaded **once** and persist in SQLite
- To force reload: Delete app or call `EmbeddingLoader.forceReload(db)`
- Provider must support embeddings (OpenAI/Google only)
- Max 5 tool calls per conversation to prevent infinite loops
- Chunks are 800 characters with no overlap

## âœ¨ Success Indicators

You'll know it's working when:
- âœ“ Console shows "9271 roots" on first launch
- âœ“ LLM uses `search_word_by_meaning` tool for meaning queries
- âœ“ LLM iterates through roots/chunks as needed
- âœ“ Accurate answers from classical Arabic dictionaries
